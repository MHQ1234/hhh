{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列表基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = [1,2]\n",
    "d = [3,4]\n",
    "cc = c*2 # 列表数乘返回元素成倍数拼接的列表\n",
    "cd = c + d # 列表相加返回拼接后的列表\n",
    "print(aa,ab,cc,cd)\n",
    "\n",
    "a = [1,2,3]\n",
    "del a[1] # del 函数用于删除列表中的元素\n",
    "print(\"new_a\", a)\n",
    "\n",
    "b = [1,2,3]\n",
    "b[3:] = [4,5] # 列表无法直接通过索引超出长度范围的位置进行赋值，但是可以通过切片方法进行赋值，即进行切片范围索引赋值，不仅可以在原有基础上列表长度，还可以在中间插入新的列表内容\n",
    "print(\"new_b\", b)\n",
    "b[5:6] = [6,7,8] # 赋值数可以不用与索引数相同，不用关心赋值数量，直接以一整块插入原列表即可\n",
    "print(\"new1_b\", b)\n",
    "b[5:6] = [4.5,5.5] # 第六个元素替换为新的元素块\n",
    "print(\"new_b2\", b)\n",
    "b[8:8] = [7.25,7.5,7.75] # 第8个元素和第9个元素之间插入新的元素块\n",
    "print(\"new_b3\", b)\n",
    "b[3:] = [] # 删除从第4个元素起的所有元素（列表同时也会缩小），列表重回最开始的样子\n",
    "print(\"new_b4\", b)\n",
    "# 通过切片范围索引更改列表与通过单值索引更改列表的区别在于：后者只能对某个元素值进行更改，不能超范围索引赋值（不能扩大列表），如果在一个位置赋值多个元素，那么它们也会变成含有多个值的一个元素\n",
    "b[2] = [7,7,7]# 如果直接使用一般数值索引插入一个元素块的话，只能得到一个元素，有个元素块显示为一个元素\n",
    "print(\"new_b5\",b)\n",
    "b[0] = 1# 正确的表达\n",
    "b[0:1] = 1# 列表不允许对切片范赋值一个整数，会报错，数组可以如此。\n",
    "\n",
    "x = [1,2]\n",
    "x.append(3) # 列表元素的扩充函数，一次只能扩充一个值\n",
    "print(x)\n",
    "x.append([1,2]) # 这样输入列表只会输出一个增加了一个元素的新列表，这个元素是[1,2]，而不是加两个，列表长度也只加了一个单位。\n",
    "print(x)\n",
    "y = [6]\n",
    "x.append(y) # 这个函数的特性使得这样的输入也会出现上面的情况，只有直接输入数值才可以。\n",
    "print(x)\n",
    "x.extend([3,4]) # 这个函数可以实现正常拼接,此函数可以完全替代append函数\n",
    "print(x)\n",
    "\n",
    "x.clear() # 清空列表\n",
    "x[:] = [] # 清空列表\n",
    "\n",
    "a = [1,2,3]\n",
    "b = a\n",
    "b[1] = 4 # 此时操作b表仍然会对a表进行同时操作\n",
    "print(\"new_a\",a)\n",
    "a = [1,2,3]\n",
    "b = a.copy() # 通过这种方法再对b表操作，不会影响a表，b相当于副本\n",
    "b[1] = 4\n",
    "print(\"new_a1\",a)\n",
    "\n",
    "print([1,1,2,2,2,3,3,3].count(1))\n",
    "print([1,[1],2,[2,2],[3,3,3]].count([1]))# 用来给列表内的元素计数，直接输入数值即可，如果加[]则默认计数有[]的元素，也可以给字符串计数\n",
    "sum([1,1,2,2,2,3,3,3] == 1)# 也可以这样计数，事实上这样的用途更广，因为count函数只用于列表，不能用于数组，而这种指令都可以使用\n",
    "\n",
    "a = [1,2,1,1,1,5,6]\n",
    "b = a.index(1) # 返回列表a中元素\"1\"的位置，这个函数可以返回列表中某个元素的位置，但要注意，首选返回的位置计数也是从0开始的，然后如果列表中没有输入的元素，就会报错\n",
    "c = a.index(1,4,6)# 在a的索引值从4-5的位置的元素中找元素1的索引值\n",
    "print(\"1.index\",b)# 如果列表中有很多个相同元素，则只返回第一个的位置\n",
    "\n",
    "a = [1,2,3]\n",
    "print(a.pop()) # 删除列表最后的元素，并同时返回删除的元素值。\n",
    "print(a.pop(1)) # 也可以指定位置删除元素，并返回该元素，输入该元素索引值即可。\n",
    "b = [1,2,1,2]\n",
    "print(b.remove(2)) # 用于删除列表中与输入的元素相同的元素，如果表中有多个相同元素，则删除从左向右的第一个该元素。\n",
    "\n",
    "x = [1,2,3]\n",
    "x.reverse() # 反向排列列表中所有元素，不返回任何值\n",
    "print(\"new_x\",x)\n",
    "y = x.reverse() # 这种方法是不对的，y只会是个空值，什么都不会返回\n",
    "y = x.copy()\n",
    "y.reverse() # 先创建一个x的副本，再进行操作才行。这种情况适用于想得到一个新的列表，内部元素是原列表的反向排列，但是不想改动原列表。\n",
    "y = list(reversed(x))# 这是另一种方法，使用reversed函数来操作，返回x的颠倒序列，但是类型是reversed类型，需要转化为列表才可查看\n",
    "\n",
    "a = [1,5,3,6,9,9]\n",
    "a.sort() # 对列表a中元素进行从小到大的排序，注意：这个函数和上面的reverse()函数一样，不能返回值\n",
    "a.sort(reverse = True) # 对列表a中的元素从大到小排列\n",
    "list(sorted(a))# 道理同reversed函数相同\n",
    "\n",
    "index_all(a, x) # 自制函数，用于返回列表a中元素x出现的所有位置（以列表形式返回）\n",
    "def index_all(a,x):\n",
    "    if isinstance(a,list): # isinstance(a,(list,int,,,,,))判断a是否是括号里诸多类型之一，如果是则返回true\n",
    "        a_index = []\n",
    "        a_index.append(a.index(x))\n",
    "        for i in range(len(a)):\n",
    "            if len(a_index) < a.count(x):\n",
    "                a_index.append(a.index(x,max(a_index)+1,len(a)))\n",
    "        return a_index\n",
    "    else:\n",
    "        print(a,\"is not a list,\",\"please input a list!\")\n",
    "        \n",
    "remove_all(a,x) # 自制函数，用于删除列表a中所有指定元素x,返回删除元素后的新列表\n",
    "def remove_all(a,x):\n",
    "    if isinstance(a,list): # isinstance(a,(list,int,,,,,))判断a是否是括号里诸多类型之一，如果是则返回true\n",
    "        for i in range(a.count(x)):\n",
    "            a.remove(x)\n",
    "        return a\n",
    "    else:\n",
    "        print(a,\"is not a list,\",\"please input a list!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy包基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#经验1：numpy类型默认是整型，并且当对默认numpy对象赋值时，会将浮点数自动向下取整。要解决此问题，定义np对象时加上.astype(np.float)\n",
    "#经验2：假设a、b都是np对象，不可用a = b这种赋值方式，因为会导致其中一个被操作时另一个也会改变\n",
    "\n",
    "a = np.array([[1,2],[3,4]]) # 矩阵输入方法\n",
    "b = np.empty((2,2)) # 返回可指定形状的初始值矩阵\n",
    "c = np.arange(1,5,0.5) # 返回定步长一维数组，默认步长是1，相当于数组里的range函数，可用于for循环，但是要注意也满足切片性质\n",
    "d = np.zeros((3,4)) # 返回指定形状的0矩阵\n",
    "e = np.ones((2,3)) # 返回指定形状的元素全是1的矩阵\n",
    "f = np.eye(5) # 返回指定维度的单位方阵\n",
    "x = np.array([1,2,3],dtype = np.float64) # dtype可以指定数组类型，如果不指定，python会根据内容默认分配类型\n",
    "y = x.astype(np.int) # astype函数可以更改数组的类型，并返回更改后的数组，但是注意，他不会对原数组进行更改，只会生成更改的副本\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "b = np.array([3,4,5,6])\n",
    "ab = a + b # 数组相加返回对应元素之和，减法同理\n",
    "ba = a/b # 数组相除返回对应元素相除，乘法同理（实用！）\n",
    "aa = a*2 # 数组数乘返回对应元素数乘后的数组\n",
    "a - 1 # 数组和标量数值进行运算，等于数中每个元素与这个标量值进行运算（实用！）\n",
    "a[[1,2]] # 返回a的第2和第3个元素\n",
    "c = np.arange(16).reshape((4, 4))\n",
    "c - [1, 2, 3, 4] # c中的每一行元素都分别减去1, 2, 3, 4（被减的可以是列表，数组和数值）\n",
    "\n",
    "# 逻辑索引是很常用的索引手段如x[x ！= 1]返回满足条件的所有元素，但是如果索引时候想对缺失值nan进行剔除，不能使用x[x!=np.nan],这样返回的结果都是ture\n",
    "# （接上）这样会取出所有元素，包括nan.正确的做法是使用函数np.isnan(x),如下：\n",
    "np.isnan(x) # 对数组x中所有元素进行是否为nan值的判断，并返回逻辑值\n",
    "# x[np.isnan(x) == False],这个命令可以取出x中所有非nan的值\n",
    "\n",
    "aa = np.array([[1,2,3],[4,5,6]])\n",
    "bb = aa.T# 用于数组转置，也可以用a.transpose()语句,返回转置后的副本，不改变aa的值\n",
    "cc = np.dot(bb, aa)# np.dot()用于计算矩阵乘法，需要自己调整矩阵行列数\n",
    "dd = aa.reshape((1,6))# reshape函数用于改变数组形状, 返回改变后的副本，不改变原对象\n",
    "np.sqrt(aa)\n",
    "np.exp(aa)\n",
    "np.square(aa)# np下面的简单计算，类似还有很多，不一一列举，都是数量层面的计算\n",
    "xx = np.array([[3,2,1],[6,5,4]])\n",
    "np.maximum(aa,xx)# 返回两个数组对应位置的最大值\n",
    "np.minimum(aa,xx)# 返回两个数组对应位置的最小值\n",
    "np.add(aa,xx)# 两个数组对应元素相加，类似这种函数有很多，不一一列举\n",
    "\n",
    "np.where(aa>3,xx,aa)# 第一个参数作为逻辑判定，是则返回第二个参数中对应的值，否则返回第三个参数对应的值，后面两个参数可以只是标量，返回的类型和形状由第一个参数决定\n",
    "# 当遇到多层选择问题时候，可以利用此函数进行嵌套操作，类似于excel中的if(,,if(,,if(,,)))\n",
    "\n",
    "m = np.array([1, 2])\n",
    "n = np.array([3, 4])\n",
    "np.hstack([m, n]) # 将两个数组水平拼接（矩阵也可， 需要行数相同，m在左）\n",
    "np.vstack([m, n]) # 将两个数组竖直拼接（矩阵也可， 需要列数相同，m在上）\n",
    "\n",
    "a = np.random.uniform(1,10,(2,5))\n",
    "np.sum(a)# 数组所有元素求和\n",
    "np.sum(a,axis = 0)# 数组分列求和\n",
    "np.sum(a,axis = 1)# 数组分行求和\n",
    "# 注意，sum函数可以通过逻辑索引进行元素计数操作！\n",
    "np.mean(a)#数组所有元素求均值\n",
    "np.mean(a,axis = 0)# 数组分列求均值\n",
    "np.mean(a,axis = 1)# 数组分行求均值\n",
    "np.std(a)# 数组所有元素求标准差，默认是除以n\n",
    "np.std(a,ddof = 1,axis = 1)# 数组分行求标准差，除以n-1\n",
    "np.std(a,ddof = 0,axis = 0)# 数组分列求标准差，除以n\n",
    "np.var(a,ddof = 1,axis = 0)# 同上\n",
    "np.cumsum(a)# 数组所有元素累计求和，每个元素是自己与之前所有元素的加和，按行的顺序进行\n",
    "np.cumsum(a,axis = 0)# 数组按列累计求和\n",
    "np.cumprod(a)# 数组累计求积，同上\n",
    "np.max(a)# 数组所有元素最大值\n",
    "np.min(a)# 数组所有元素最小值\n",
    "np.argmax(a)# 返回数组所有元素中最大的索引值，按行顺序进行\n",
    "np.argmax(a, axis = 0)# 按列返回数组每列最大元素的索引值\n",
    "np.argmin(a)# 同上\n",
    "# 接下来的知识点很重要！！！\n",
    "# 以上的函数前面都可以加一个nan如np.nansum(),表示在对数组进行运算时候，忽略数组中的nan缺失值，只对正常值进行运算！\n",
    "# 注意，所有以上操作不对数组a进行改变\n",
    "np.any(a >= 0)# 如果括号内逻辑判定有至少一个true，则函数返回true,否则返回false\n",
    "np.all(a >= 0)# 如果括号内逻辑判定全部都是true，则函数返回true,否则返回false\n",
    "sorted(np.array([3, 1, 2]), reverse = True)# 数组排序，跟在列表中使用方法相同，TRUE代表从大到小排序,注意，这个函数是内置函数，不能用numpy来调用\n",
    "# 数组和列表同样可以使用sort函数，但是对于内置函数reverse，只有列表可以使用，数组不能使用。\n",
    "set([3, 1, 2]) # 剔除数组a中重复的元素,返回不重复的元素，并以从小到大排序形式输出，注意：该函数不会改变a，只是返回处理后的副本，还有该函数返回的是set型，不适用于数组运算，不建议使用。\n",
    "# set函数是内置函数，不需要调用，并且在列表中同样使用。\n",
    "np.unique(a)# 此函数作用和set函数相同，但是返回的是数组型，针对数组使用很好，任何形状的数组都可以使用\n",
    "\n",
    "m = np.array([1,2,3,4,5])\n",
    "n = np.array([3,4,5,6,7,8])\n",
    "np.intersect1d(m,n)# 按顺序返回数组m和数组n交集的元素\n",
    "np.union1d(m,n)# 按顺序返回m和n的并集的元素\n",
    "np.setdiff1d(m,n)# 按顺序返回m中有但是n中没有的元素\n",
    "np.setxor1d(m,n)# 按顺序返回m,n并集减去m,n交集的元素\n",
    "\n",
    "np.random.seed(0)\n",
    "a = np.random.randn(5,5)\n",
    "b = a.T\n",
    "np.dot(a,b)# 计算并返回a,b矩阵的乘积，这个函数是np直接调用\n",
    "np.linalg.inv(a)# 计算并返回矩阵a的逆矩阵,不能直接用np调用\n",
    "np.linalg.det(a)# 计算并返回矩阵a的行列式值，不能直接用np调用\n",
    "m,n = np.linalg.eig(a)# 计算并返回矩阵a的特征值和特征向量，不能用np直接调用\n",
    "np.linalg.solve(a,n[0])# 求解线性方程组的解向量，a是系数矩阵，注意，此函数只能解有唯一解的方程组，不然会报错\n",
    "\n",
    "a = np.random.normal(0,1,(3,3))# 生成服从期望是0，标准差是1的正态分布的3x3随机矩阵\n",
    "a = np.random.randn(3,3)# 固定生成指定形状的标准正态分布随机数组\n",
    "a = np.random.uniform(1,10,(3,3))# 生成服从1-10之间均匀分布的3x3随机矩阵\n",
    "a = np.random.rand(3,3)# 固定生成0-1形状的随机数组\n",
    "a = np.random.binomial(10,0.3,5)# 生成服从b(10,0.3)分布的代表成功次数的随机数，5是指重复上述过程5次，返回5个随机数\n",
    "a = np.random.binomial(10,[0.1,0.2,0.6,0.7])# 将多个二项分布过程写在一个函数中，对于每个概率都进行一次随机试验，返回每个试验生成的随机数\n",
    "a = np.random.binomial(10,[0.1,0.2,0.6,0.7],(1,4))# 与上个函数相同，第三个参数默认为此，维度上必须与概率列表相同\n",
    "a = np.random.binomial(10,[0.1,0.2,0.6,0.7],(4,4))# 将上述过程重复试验4次\n",
    "np.random.shuffle(a)# 对数组a中的元素进行随机排列，矩阵形式也可以，所有元素一起重排。注意，这个函数直接对a进行更改，且不返回任何值。\n",
    "\n",
    "a = np.random.randint(3,5,(3,3))# 从3,4两个整数中随机抽取一个整数，并重复多次形成3x3的矩阵（默认是一个数）注意，对于范围设定一定是切片化的！此函数可进行整数的多次放回抽取，但是只限于对某个范围操作，不能对某个数组里的元素直接进行抽取，但是可以抽取他们的编号。\n",
    "a1 = np.array([3,5,2.6,41.2,5.7])\n",
    "a2 = np.random.choice(a1, 3, replace = False, p = [0.2, 0.1, 0.3, 0.4, 0.0])# 此函数可对某个数组进行随机抽取操作，对a1数组中的每个元素以一定概率抽取，共抽取三个元素，FALSE表示不放回抽取。概率参数默认都是相同的\n",
    "a = random.sample(list(a1),3)# 此函数可从某个列表中不重复随机抽取指定数量的元素,注意，需要调用random包，操作对象必须是列表，不能自定义抽取概率。函数返回值是一个列表，可以把其插入数组中或者将其转为数组\n",
    "# 列表插入数组时，必须使用索引:的情况才可以，直接点对点赋值也必须使用:写法，不然无法成功！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#pandas API链接：https://pandas.pydata.org/pandas-docs/stable/reference/\n",
    "# Series对象基础知识\n",
    "\n",
    "a = pd.Series([1, 2, 3]) # （首字母大写）创建标签+数组对象. 注意，被创建的个体可以是列表，也可以是数组\n",
    "a.values # 返回该对象的数组值\n",
    "a.index # 返回该对象的索引值\n",
    "b = pd.Series([4, 5, 6], index = ['a', 'b', 'c']) # 可自行设置索引值\n",
    "b.name = 'hello' # 每个Series对象都可以设置一个名字\n",
    "b = pd.Series([4, 5, 6], index = ['a', 'b', 'c'], name = 'hhh') # 可直接设置对象名\n",
    "b.index.name = 'aaa' # Series的索引值可以设置属性标签\n",
    "b.index = ['f', 'g', 'k'] # 可以自行更改Series对象的索引值\n",
    "# d.index[1] = 'gg' # 错误！可以对索引进行整体赋值，但是不能对个别位置元素进行更改\n",
    "b['k'] # 返回b中索引值b对应的元素值，与b[1]得到的结果相同\n",
    "b.k # 与上述操作等价\n",
    "b[['f', 'k']] # 根据标签索引多个值时候的写法，注意，b['a', 'b']这种写法是错的\n",
    "b['f':'k'] # 从索引值为f的行到索引值为k的行全部取出\n",
    "b[1] # 也可以按照数值顺序进行索引，但是返回的只有数值，不是series类型\n",
    "b[0:2] # 通过切片数值索引可以返回series类型的结果\n",
    "\n",
    "b[b > 4]\n",
    "b * 2\n",
    "np.mean(b) # 可以对b进行数组的运算，返回的结果都是带有索引值的数组\n",
    "a + b # 与数组计算不同的一点是数组可认为都是默认相同的0-N的索引，但是Series对象带有个性索引值，两个对象直接相加时会按照索引来加，如果索引不同，不会相加\n",
    "\n",
    "data = {'a': 10, 'b': 20, 'c': 30}\n",
    "d = pd.Series(data) # 也可以直接根据字典创建Series对象\n",
    "d = pd.Series(data, index = ['c', 'a', 'b']) # 可以通过自己改动字典的索引位置调整Series对象输出顺序\n",
    "\n",
    "pd.isnull(d) # 用于判断d中每个索引对应的元素是否是空值，是输出TRUE，不是输出false,也可以写作d.isnull()\n",
    "pd.notnull(d) # 用于判断d中每个索引对应的元素是否是空值，是输出false，不是输出true,也可以写作d.notnull()\n",
    "\n",
    "# Dataframe对象基础知识\n",
    "\n",
    "data = {'a': [1, 2, 3, 4], 'b': [1, 1, 1, 1], 'c': [2, 2, 2, 2]}\n",
    "df = pd.DataFrame(data) # （注意D F要大写）数据框可以直接依靠字典来生成，同样的方法如果用于Series也只会生成一列数据\n",
    "# DF对象和Se对象一样会自动安排索引0-N（未指定索引情况下）\n",
    "df = pd.DataFrame(data, columns = ['c', 'b', 'a']) # 可以手动调整列的顺序\n",
    "df = pd.DataFrame(data, index = ['hh', 'aa', 'ee', 'kk']) # 添加行名\n",
    "df.values # 取出df中所有元素, 返回一个数组类型\n",
    "df.columns # 查看df的列名\n",
    "df.index # 查看df的行名\n",
    "df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], index = ['a', 'b', 'c'], columns = ['h', 'hh', 'hhh']) # 比较全面的数据框生成指令\n",
    "# 数组，字典，列表都可以生成DF对象\n",
    "df.index.name = 'qq' # 设置行标签属性名\n",
    "df.columns.name = 'ww' # 设置列标签属性名\n",
    "df['hh'] # 按列索引返回一个Series型的值,不可以直接按行标签索引，也不能直接用数值索引内部元素\n",
    "df['hh'] = 8 # 将hh列所有元素变为8\n",
    "df['h'] = np.arange(3) # 将h列元素进行重新赋值为0-2\n",
    "# 对DF对象内部元素赋值时候，无论是数组型还是列表型都接受赋值，但是使用type(df['h'].values)语句查看该列元素值的类型时候返回的是数组型\n",
    "df.h # 用\".\"来进行整列的索引更加方便\n",
    "df.h['a']\n",
    "df.h.a # 可以用这样的方式取出df的元素，先列后行进行名称索引（相当于先调出series型的列，再对列进行索引取值）\n",
    "df.h[1] # 这样也是可以的，只要先把列名调出来就行\n",
    "df[1:2] # 虽然通过标量值索引不了，但是可以通过数值切片索引对数据框的行进行获取，但是仅限于行，不能引申到列\n",
    "df[[True, False, True]] # 还可以通过逻辑值来对行进行索引，但是仅限于行\n",
    "df[df.hh > 1] # 通过对指定列的判定返回逻辑值，再根据逻辑值对行进行索引，可以通过这种办法实现根据列的条件选择行\n",
    "df[df > 2] = 0 # 首先通过判定所有元素值与2的大小在数据框的每个位置得到逻辑值，然后对所有为true的位置赋值为0\n",
    "\n",
    "# 重点！！！loc[]和iloc[]函数\n",
    "df.loc['a', 'h']\n",
    "df.loc[['a', 'b'], ['h', 'hhh']]\n",
    "df.loc['a':'c', 'h':'hhh']\n",
    "# loc函数可以以行列名的方式任意索引数据框中的值，但是不能进行数值索引\n",
    "df.iloc[1, 2]\n",
    "df.iloc[[1, 2], [1, 2]]\n",
    "df.iloc[0:2, 0:3]\n",
    "# iloc[]函数可以以数值索引方式任意获取数据框中的值，但是不能进行行列名称索引\n",
    "\n",
    "# pandsa包基本功能\n",
    "\n",
    "# 重新索引函数reindex\n",
    "b = pd.Series([4, 5, 6], index = [1, 2, 3], name = 'hhh')\n",
    "bb = b.reindex([1, 2, 3, 4]) # reindex函数用于对索引重新排列，如果出现索引值对不上就返回NAN\n",
    "bb = b.reindex([1, 2, 3, 4], fill_value = 0) # 将返回的NAN全部填补为0\n",
    "bb = b.reindex([1, 2, 3, 4], method = 'ffill') # 将返回NAN的位置向前填充，即跟他前一个元素相同(bfill是向后填充)\n",
    "\n",
    "frame = pd.DataFrame(np.arange(9).reshape((3,3)), index = ['a', 'c', 'd'], columns = ['aa', 'cc', 'dd'])\n",
    "frame1 = frame.reindex(['a', 'b', 'c', 'd'], method = 'ffill') # 对数据框的行进行重排（默认对行）并对NAN值进行向前填充\n",
    "frame2 = frame.reindex(columns = ['aa', 'bb', 'cc', 'dd'], method = 'ffill') # 对数据框的列进行重排（需要特别指定columns）并对NAN值进行向前填充\n",
    "frame3 = frame.reindex(index = ['a', 'b', 'c', 'd'], columns = ['aa', 'bb', 'cc', 'dd'], method = 'ffill') # 对行列都进行重排，但是method方法在这种情况下只能对行进行应用\n",
    "frame3 = frame.reindex(index = ['a', 'b', 'c', 'd'], columns = ['aa', 'bb', 'cc', 'dd'], fill_value = 0) # fill_value方法可以对所有NAN值进行填充\n",
    "\n",
    "# 丢弃函数drop()\n",
    "obj = pd.Series(np.arange(4), index = ['a', 'b', 'c', 'd'])\n",
    "data = pd.DataFrame(np.arange(12).reshape((3,4)), index = ['a', 'b', 'c'], columns = ['one', 'two', 'three', 'four'])\n",
    "obj.drop(['a']) # 删除Series中索引值为a的条目\n",
    "obj.drop(['a', 'd']) # 删除多个条目\n",
    "data.drop(['a', 'b']) # 删除数据框中的两行（默认是删除行）\n",
    "data.drop(columns = ['one', 'four']) # 删除数据框两列（必须指明是列）\n",
    "data.drop(['one', 'four'], axis = 1) # 与上条命令作用相同\n",
    "data.drop(index = 'a', columns = 'one') # 同时删除行列条目\n",
    "# 不能通过数值索引和:方式来删除，只能通过上述方式\n",
    "\n",
    "# Series和DataFrame各自进行四则运算方法\n",
    "s1 = pd.Series(np.arange(4), index = ['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series(np.arange(1, 6), index = ['a', 'c', 'd', 'f', 'g'])\n",
    "d1 = pd.DataFrame(np.arange(12).reshape((3, 4)), index = ['a', 'b', 'c'], columns = ['one', 'two', 'three', 'four'])\n",
    "d2 = pd.DataFrame(np.arange(16).reshape((4, 4)), index = ['a', 'c', 'd', 'e'], columns = ['one', 'five', 'six', 'nine'])\n",
    "s1 + 2 # 所有元素都+2,减乘除同理\n",
    "d1 + 2 # 所有元素+2，减乘除同理\n",
    "s1 + s2 # 两个Series类型相加，返回结果的索引取二者并集，索引相同的话返回元素对应相加值，不同的话返回NAN\n",
    "d1 + d2 # 同上\n",
    "s1.add(s2, fill_value = 0) # 加法公式，可以进行缺失值填充\n",
    "s1.sub(s2, fill_value = 0) # 减法公式， 可以进行缺失值填充\n",
    "s1.mul(s2, fill_value = 0) # 乘法公式， 可以进行缺失值填充\n",
    "s1.div(s2, fill_value = 0) # 除法公式， 可以进行缺失值填充\n",
    "d1.add(d2, fill_value = 0) #同上\n",
    "d1.sub(d2, fill_value = 0) #同上\n",
    "d1.mul(d2, fill_value = 0) #同上\n",
    "d1.div(d2, fill_value = 0) #同上\n",
    "\n",
    "# DataFrame和Series之间的运算\n",
    "d2 = pd.DataFrame(np.arange(16).reshape((4, 4)), index = ['a', 'b', 'c', 'd'], columns = [1, 2, 3, 4])\n",
    "s1 = pd.Series(np.arange(4), index = [1, 2, 3, 5])\n",
    "d2 - s1 # 首先把s1的索引对应到d2的列名称，如果对的上，d2中所有行的元素减去s1中的元素，对不上的变为NAN（注意，只要有一方对不上，就会显示NAN）\n",
    "d2.sub(s1) # 作用同上\n",
    "s1.index = ['a', 'b', 'c', 'e']\n",
    "d2.sub(s1, axis = 0) # 想要把s1的索引对应到d2的行名中（即让d2的每一列减去s1），必须要用函数操作，且设置参数值axis = 0, 默认值是1\n",
    "\n",
    "\n",
    "# 以下所有函数都也可用于obj对象，这些函数基本都可以用np.来代替，返回的类型也一样，但是诸如idxmax这种函数是np中不具备的，所以尽量用下面的写法\n",
    "frame.sum(axis = 1)\n",
    "frame.mean(axis = 1)\n",
    "frame.median(axis = 1) # 中位数\n",
    "frame.min(axis = 1)\n",
    "frame.max(axis = 1)\n",
    "frame.mad(axis = 1) # 平均离差绝对值\n",
    "frame.var(axis = 1) # 默认是除以n-1\n",
    "frame.std(axis = 1) # 默认是除以n-1\n",
    "frame.cumsum(axis = 1)\n",
    "frame.cumprod(axis = 1)\n",
    "frame.cummin(axis = 1)\n",
    "frame.cummax(axis = 1)\n",
    "frame.idxmax(axis = 1) # 返回每一行最大元素所对应的列索引\n",
    "frame.idxmin(axis = 1) # 返回每一行最小元素所对应的列索引\n",
    "frame.count(axis = 1) # 返回，每一行元素中非NAN的个数\n",
    "frame.pct_change(axis = 1) # 计算每行中每个元素相比较上一个元素的增长率（默认是对列）\n",
    "frame.diff(axis = 1) # 计算每行元素相对自己左边一位元素的一阶差分值（默认对列）\n",
    "obj.argmax() # 这个函数一般只用于Series对象，因为在DF中不能做到分行列应用\n",
    "# 以下只能用于数据框\n",
    "frame.corr() # 计算列与列间的相关系数(只能对列进行操作)\n",
    "frame.cov() #  计算列与列间的协方差（只能对列进行操作）\n",
    "frame.corrwith(frame.c) # 一个数据框与另一个Series或者数据框的协方差运算，如果是Series则需要其索引与frame.index相同，返回其与frame的每一列的相关系数\n",
    "# 如果是DF对象，则按照两个数据框的列名进行配对，然后分别计算配对好的列的相关系数并返回\n",
    "# 还有很多，不尽列举\n",
    "\n",
    "# pandas对象的排序\n",
    "obj = pd.Series([4, 9, 6, 20, 4], index = ['d', 'a', 'e', 'b', 'c'])\n",
    "frame = pd.DataFrame(np.array([3, 5, 2, 6, 9, 23, 12, 34, 12, 15, 11, 0]).reshape(3, 4), columns=['c', 'f', 'd', 'a'], index = ['C', 'A', 'B'])\n",
    "obj.sort_index() # 将obj对象按照索引进行排序\n",
    "obj.sort_values() # 将obj对象按照值进行升序排序\n",
    "obj.sort_values(ascending = False) # 将obj对象按照值进行降序排序\n",
    "frame.sort_index() # 将frame对象按照行索引进行行升序排序（默认）\n",
    "frame.sort_index(axis = 1) # 将frame对象按照列索引进行列升序排序\n",
    "frame.sort_index(axis = 1, ascending = False) # 将frame按照列索引进行列降序排序\n",
    "frame.sort_values(by = 'c') # 将frame对象按照第c列的值进行行升序排序\n",
    "frame.sort_values(by = 'A', axis = 1) # 将frame对象按照第A行的值进行列升序排序\n",
    "frame.sort_values(by = ['c', 'd'], ascending = [False, True]) # 将frame对象依次按照第c,d两列的值进行行降序和升序排序（先按照c列值排）\n",
    "\n",
    "obj.index.is_unique # 判断obj对象的索引有无重复值\n",
    "obj.is_unique # 判断obj对象的元素有无重复值\n",
    "frame.columns.is_unique # 判断frame对象的列索引有无重复值\n",
    "frame.index.is_unique # 判断frame对象的行索引有无重复值\n",
    "frame.c.is_unique # 判断frame对象的第c列的元素有无重复值\n",
    "frame.loc['A'].is_unique # 判断frame对象的第A行元素有无重复值\n",
    "# frame.is_unique这个方法是错误的，frame.values.unique也是不可取的，numpy包中不含有这个函数\n",
    "# 以下两个函数仅针对Series对象使用\n",
    "obj.value_counts() # 计算Series对象中的元素值出现的频数，并且按照频数从高到低的顺序返回元素值和对应频数\n",
    "obj.unique() # 返回Series对象中不重复的元素，按照发现的顺序进行返回，不进行数值排序\n",
    "\n",
    "# 处理缺失数据\n",
    "data.isnull()#判断是否有缺失值，每个元素的位置都返回TRUE或FALSE\n",
    "data.notnull()#与上条返回结果相反\n",
    "data.h.isnull()#可用于单列判断，然后进行条件筛选\n",
    "\n",
    "data = pd.Series([1, np.nan, 3.5, np.nan, np.nan]) \n",
    "data1 = pd.DataFrame([[1, 6.5, 3], [1, np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, 6.5, 3]])\n",
    "data.dropna() # 返回data中没有缺失值的索引和元素，返回副本\n",
    "data[data.notnull()] # 与上述作用相同\n",
    "data1.dropna() # 返回data1中没有缺失值的列（默认）\n",
    "data1.dropna(axis = 1) # 返回data1中没有缺失值的行\n",
    "data1.dropna(how = 'all') # 返回data1中不全是缺失值的列\n",
    "data1.dropna(axis = 1, how = 'all') # 返回data1中不全是缺失值的行\n",
    "\n",
    "data.fillna(0) # 将data中的缺失值填充为0并返回副本\n",
    "data.fillna(method = 'ffill') # 将data中缺失值进行向前填充（bfill是向后填充）\n",
    "data.fillna(method = 'ffill', limit = 1) # 将data中缺失值进行向前填充，但限制次数，对于每一个被当做填充基准的元素，所填充缺失值次数有上限，但是如果每个缺失值都有不同的填充基准，那么不会限制\n",
    "data.fillna(method = 'ffill', limit = 1, inplace = True) # 上述操作只能返回副本,加上inpalce = TRUE 可以直接更改data,不返回对象\n",
    "data1.fillna(method = 'ffill', axis = 0) # 将数据框data1的缺失值按照行的顺序进行向前填充（默认是按照行的顺序，可以不输入axis = 0）\n",
    "data1.fillna(method = 'ffill', axis = 1) # 将数据框data1的缺失值按照列的顺序进行向右填充\n",
    "data1.fillna(method = 'ffill', limit = 1) # 将数据框data1的缺失值按照行的顺序进行向前填充，但是限制每一个基准的填充次数\n",
    "data1.fillna({0:8, 1:0, 2:9}) # 将data1的不同列设置不同的填充值，第一列缺失值填充为8，第二列为0，第三列为9\n",
    "data1.fillna(0, inplace = True) # 直接更改data1,不返回副本\n",
    "\n",
    "#读取数据\n",
    "data = pd.read_csv('')\n",
    "#分组计数并返回结果\n",
    "data.value_counts()\n",
    "#数据简单统计（返回各列的各种分位数均值计数等信息）\n",
    "data.describe()\n",
    "\n",
    "#pandas字符串操作，涉及方法很多，详细操作需要查看API\n",
    "#API链接：https://pandas.pydata.org/pandas-docs/stable/reference/series.html#string-handling\n",
    "data.h.str# .str是pandas专门针对series对象的方法，不能直接对df或者values对象使用，这条语句返回的是属性名称\n",
    "data.h.str.replace('1','').astype(int) #比如转化为str类型后进行字符串替换，然后转为数值型\n",
    "data.h.str.replace('[1,2,3]','')#多值替换，将1,2,3都替换为空\n",
    "#注意：当一次无法完成所有替换时候，除了上一条，也可以分多次替换，具体见下文的链式操作！\n",
    "#关于str的子方法有很多，比如：\n",
    "data.h.str.len()#统计字段维度数\n",
    "data.h.str.isnumeric()#判断字段各个元素是不是数值型\n",
    "data.h.str.slice(0,2)#截取字符串\n",
    "data.h.str[0:2]#截取字符串的另一种写法\n",
    "#.str的链式操作（重要）！\n",
    "data.h.str.replace('-','').slice(0,2)#错误\n",
    "data.h.str.replace('-','').str.slice(0,2)#正确，str的操作必须早str属性下进行，不能再series下进行，所以需要再.str一次\n",
    "\n",
    "\n",
    "# merge连表，相当于sql的join\n",
    "pd.merge(left, right, how = 'inner', on = None, left_on = None, right_on = None, left_index = False, right_index = False\n",
    "        , sort = True, suffixes = ('_x','_y'))\n",
    "# left, right:要merge的df或者有名字的series结构\n",
    "# how:join类型，'left', 'right', 'outer', 'inner'\n",
    "# on: join的key,left和right都需要有这个key\n",
    "# left_on: left的df或者series的key\n",
    "# right_on：right的df或者series的key\n",
    "# 注：当两个数据集使用相同名字的字段进行连接时候，使用一个on = 就可以，否则需要用left_on和right_on\n",
    "# left_index, right_index: 使用index而不是普通的column做join，默认是FALSE不使用\n",
    "# suffixes: 两个元素的后缀，如果列有重名，默认是('_x','_y')\n",
    "\n",
    "\n",
    "# concat拼接表，可横向也可纵向拼接\n",
    "\n",
    "pd.concat(objs, axis = 0, join = 'outer', ignore_index = False)\n",
    "# objs: 一个DataFrame或者Series的组合列表，一般采用[a,b,c,...]的形式，将里面的对象进行拼接\n",
    "# axis: 默认是0代表按行合并（添加行），如果等于1代表按列合并（添加列）\n",
    "# join: 合并的时候索引的对齐方式，默认是outer join，也可以是inner join\n",
    "# ignore_index: 是否忽略掉原来的数据索引\n",
    "\n",
    "# groupby分组数据统计\n",
    "df.groupby('A').sum() #对df对象按照A字段进行分组，然后统计每组内其他字段的求和\n",
    "#注：sum()可换成其他统计函数；输出结果中其他字段不会自动起别名；可以用apply()自见聚合函数\n",
    "df.groupby('A').apply(f) #自己创建聚合函数用于分组统计计算\n",
    "#分组字段超过一个时以索引形式呈现，自动成为多级行索引，以前的行索引被取代\n",
    "df.groupby(['A','B'], as_index = False).sum() #分组字段不会以二级索引形式显示，而是和sql中一样\n",
    "df.groupby(['A','B']).sum().reset_index() #与上调命令有相同效果\n",
    "df.groupby(['A','B']).sum() #按照两个字段分组的情况\n",
    "df.groupby('A').agg([np.sum, np.mean, np.std]) #按照A字段分组后对每个字段进行三种统计\n",
    "df.groupby('A').agg({'B':np.sum, 'C':np.mean, 'D':np.std}) #按照A分组后，对BCD三个字段分别进行不同的统计\n",
    "df.groupby('A').sum()['B'] #按照A分组后，只显示对B求和统计的结果\n",
    "df.groupby('A').agg({'B':np.sum}) #与上个命令效果相同，agg是万能的，建议都按照agg写\n",
    "df.groupby('A')['B'].sum() #与上一条作用相同\n",
    "#分组后重命名，有很多办法，这里介绍一种，更多去CSDN中找\n",
    "df.groupby(['A','B']).agg({'C':np.sum, 'D':np.mean}).rename(columns = {'C':'Sum_c', 'D':'Mean_d'})\n",
    "#注：以上各个命令都可以在最后面加一个.plot(),可以分组画图，但是要先加一个命令 %matplotlib.inline\n",
    "\n",
    "# 多级索引下的数据筛选，分组之后分组字段形成行索引，此时如果要筛选数据，有两种办法\n",
    "#首先，当只有一个分组字段时候，分组字段为行索引，直接.loc[]就可\n",
    "data.loc[[a1,a2], C]\n",
    "#如果是多个分组字段，行索引是多级索引，有如果下两种方式\n",
    "data = df.groupby(['A','B']).sum() #先创建一个分组聚合数据集\n",
    "data.loc[([a1,a2], [b1,b2]),C] #假设a1a2是A字段下的两个值，b1b2是B字段下的两个值，此时该值是行索引的值，返回结果是a1a2在b1b2时的C字段的统计结果\n",
    "#注：(a,b,...)是多个级别索引的筛选，每个级别下若进行多值筛选则用[a1,a2]的手段，对于列索引，直接输入列的字段名即可\n",
    "#注：如果只有多级索引只使用一个，可以当成只有一个分组索引那样写\n",
    "data.reset_index().loc[((df.A = a1)|(df.A = a2)) & ((df.B = b1)|(df.B = b2)),C] #此时失去了分组索引，分组索引变成正常的字段，需要靠逻辑值来筛选数据\n",
    "\n",
    "# set_index和reset_index\n",
    "# set_index: https://blog.csdn.net/weixin_45144170/article/details/106314272\n",
    "# reset_index: https://blog.csdn.net/xiewenrui1996/article/details/109055070\n",
    "\n",
    "#apply函数（非常重要！）\n",
    "#此函数涉及内容较多，详见如下链接：\n",
    "#链接1：https://blog.csdn.net/qq_19528953/article/details/79348929?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162531596016780262572468%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=162531596016780262572468&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~hot_rank-1-79348929.first_rank_v2_pc_rank_v29&utm_term=pandas+apply%E5%87%BD%E6%95%B0&spm=1018.2226.3001.4187\n",
    "#链接2：https://blog.csdn.net/mochou111/article/details/95311065?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162531646416780265431893%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=162531646416780265431893&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~hot_rank-2-95311065.first_rank_v2_pc_rank_v29&utm_term=pandas+apply%E5%87%BD%E6%95%B0%2Clambda&spm=1018.2226.3001.4187\n",
    "#链接3：https://blog.csdn.net/stone0823/article/details/100008619?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162531725216780265480249%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=162531725216780265480249&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~hot_rank-1-100008619.first_rank_v2_pc_rank_v29&utm_term=numpy+apply%E5%87%BD%E6%95%B0%2Clambda&spm=1018.2226.3001.4187\n",
    "# map:https://blog.csdn.net/quanlingtu1272/article/details/95482253\n",
    "\n",
    "# 如何实现Hive里面的窗口函数\n",
    "# 排序：rank(ascending = False, method = \"first\") # 第一个参数是升序降序，第二个分三种情况，first相当于row_number; min相当于rank；max不相当于dense_rank\n",
    "# df.A.rank() # 直接就能排序\n",
    "# df.A.groupby(df.C).rank() # 按C分组，每组对A排序\n",
    "\n",
    "# 窗口聚合（所有窗口聚合类函数都这么写）\n",
    "# df[\"D\"] = df.C.map(df.groupby(\"C\")[\"A\"].sum()) # 按C分组，对A求和，得到一个以C为索引的求和Series，然后用C进行map，加入到df中\n",
    "\n",
    "# lag和lead的pandas写法\n",
    "# df.A.shift(1) # 不聚合下直接滞后，shift里面的数值决定移动的方向和步长，其实也可以控制上下还是左右移动，用axis函数\n",
    "# df.A.groupby(\"C\").shift(1) # 分组移动\n",
    "\n",
    "#数据透视表\n",
    "#与仅用group by分组的区别：分组统计展示的结果中，分组字段只能以多级行索引的形式存在，但是数据透视表可以建立交叉表\n",
    "#有两种方法建立透视表，第一种是常用方法，直接根据原数据集建立数据透视表，像在excel中的操作一样；另一种是基于groupby分组聚合且分组字段为行索引时\n",
    "#常用pivot_table方法：\n",
    "data1 = pd.pivot_table(data, index = ['a', 'b'], columns = ['c', 'd'], values = ['e', 'f']\n",
    "                       , aggfunc = [np.sum,np.mean],dropna = True, margins = False, fill_value = 0)\n",
    "# data: df格式的数据\n",
    "# index: 在数据透视表中作为行索引的字段（可以有多级，也可以没有，直接不写)\n",
    "# columns: 在数据透视表中作为列索引的字段（可以有多个，也可以没有不写）\n",
    "# values: 需要被聚合度量的字段\n",
    "# aggfunc: 采用的聚合函数，一般只用一种，但也可以每个字段多个度量，还可以不同字段不同度量，默认是np.mean\n",
    "#关于aggfunc，有一个需要注意的点，如果调用的是内置函数，如count，np.count和count都是不对的，应该用'count'\n",
    "# dropna: 对全为null的字段不予度量，默认是True\n",
    "# margins: 是否对行列进行汇总计算，默认是False\n",
    "# fill_value: 对最终数据透视表中的缺失值进行填充\n",
    "#数据透视表的筛选：\n",
    "data1.query() #()里使用逻辑判断\n",
    "#最好得办法是把得到得数据透视表pd一下变成一般pandas类型，再来进行其他操作\n",
    "\n",
    "#第二种建立交叉表的办法：针对group by后有多级行索引的情况，使用unstack函数进行索引行转列\n",
    "data.groupby(['A','B']).sum().unstack(level = -1) #level是需要被作为列索引的分组字段的索引，默认是-1，就是最后一个，可设置为0等\n",
    "#上述命令后接.stack()可回归原位\n",
    "\n",
    "#列连表：交叉表的得一种，但聚合计算只是计数，有时候更方便\n",
    "pd.crosstab(a, b)\n",
    "\n",
    "#关于df对象索引的细节\n",
    "#1. 创建df索引时，无论是inde 还是columns在赋值的时候，内容必须在[]中写，即便只有一个值也要如此！！！\n",
    "#2. 更改索引时要注意：index只能整体赋值更改，如index1 = index2;不能更改其中某个值，如index[2] = 'nan',这样是错的！！！\n",
    "\n",
    "#关于df对象单行显示问题：\n",
    "#如果想只显示一行df,在用df.iloc[0,:]时候，结果不是以df形式出现，而是series形式，不方便后面的拼接操作\n",
    "#这时需要用df.iloc[0:1, :]操作，切片索引返回的仍然是df形\n",
    "\n",
    "#pd.DataFranem([1,2,3,4])默认生成一列，如果想生成一行，需要pd.DataFranem([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 变量保存技巧：大数据py导入sql数据集非常慢，为了不用每次重新读取，可将读好的数据集以变量形式保存为txt文件，下次打开直接调用文件即可\n",
    "import pickle\n",
    "#wb 读写到二进制文件\n",
    "f = open(\"./a.txt\",'wb')\n",
    "pickle.dump(df,f) #df是要保存的变量\n",
    "f.close()\n",
    "\n",
    "#好了，现在关掉程序，重新打开\n",
    "import pickle #别忘了这个\n",
    "#开始读取\n",
    "f = open(\"./a.txt\",'rb')\n",
    "df = pickle.load(f)\n",
    "f.close() #读取完毕\n",
    "df.head() #见证奇迹的时刻\n",
    "\n",
    "\n",
    "#2. zip 函数的应用（常用于将多个向量绑定在一起，形成多维映射）\n",
    "import numpy as np\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "c = zip(a,b)# 生成列表，形成a,b一一对应的关系组合，注意，形成zip列表的元素不一定是数组，也可以只是列表\n",
    "type(c)# c的类型是zip\n",
    "d = list(c)# 列表化处理便于操作\n",
    "x = [i for i,j in d if j == 6]# 可以将zip列表作为索引条件，同时记住这种for if的写法，作用是循环判定并返回值，记住这种写法\n",
    "y = [i if j == 6 else 0 for i,j in d]# 可以将zip列表作为索引条件，同时记住这种if else for的写法，作用通过循环判定返回值，记住这种写法\n",
    "y = [i for i in range(10)] # 还有这个写法也要记住\n",
    "print(x)\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c = [7,8,9]\n",
    "d = list(zip(a,b,c))\n",
    "for i,j,k in d:\n",
    "    print(i,j,k)\n",
    "# 以下方法十分重要！！！\n",
    "A = ['a', 'b', 'c', 'd', 'e']  # 出现的元素\n",
    "B = [1, 5, 0, 45, 78]  # 元素出现的次数（统计结果）\n",
    "Z = zip(B, A)  # 对AB进行封装，把频率放在前面\n",
    "Z = sorted(Z, reverse=True)  # 进行逆序排列\n",
    "B, A = zip(*Z)  # 进行解压，其中的AB已经按照频率排好\n",
    "for i,j in zip(B, A):\n",
    "    print(i,'\\t',j)\n",
    "    \n",
    "\n",
    "#3. enumerate函数的应用，将一个向量与其索引向量绑定，方便将值和其索引对应\n",
    "a = [1,2,3,4,5,6]\n",
    "for i,j in enumerate(a):\n",
    "    print(i,j)\n",
    "list(enumerate(a))\n",
    "# 此函数跟zip函数相似，返回元素都是二元元组的集合（可转为列表查看），输出元素a的索引值和元素组合。\n",
    "\n",
    "\n",
    "\n",
    "#4. 一行书写for i in range() if elif esle 语句\n",
    "#用途：1.简洁高效；2.符合特定场景下的使用，如 apply(lambda x: )场景\n",
    "#大概用法：[]中输入一行命令，根据条件判断直接返回结果，以列表形式存储返回结果\n",
    "#当没有for循环时：[结果1 if 条件1 else 结果2] 是最简单的句式，else不可或缺,例子如下：\n",
    "[1 if 2 > 1 else 0]\n",
    "#一般化句式：[结果1 if 条件1 else 结果2 if 条件2 else 结果3 if 条件3 else .....else 最后结果] ，条件和结果的代号是对应的，最后一定要有else\n",
    "#当有for循环加入时，以两层判断为例，句式如下：[结果1 if 条件1 else 结果2 if 条件2 else 结果3 for i in range(n)]\n",
    "#当有for循环加入，且只判断一次时，不是必须加else，可以这么写：[结果1 for i in range(n) if 条件1]\n",
    "\n",
    "#数据缺失值处理要注意，缺失值的种类很多， 不仅是NAN，还可能有''，以及一些特征的异常值如-9999等都可能为缺失值，需要考虑周全"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
